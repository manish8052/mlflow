{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6505a7ad",
   "metadata": {},
   "source": [
    "## What is MLFlow and its Components\n",
    "\n",
    "MLFLow is an open source platform to manage the ML lifecycle, including experimentation, reproducibility, deployment, and a central model registry. MLFLow currently offers four components:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5745f450",
   "metadata": {},
   "source": [
    "<img src=\"mlflow.png\">\n",
    "\n",
    "\n",
    "https://www.mlflow.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f44a8b9",
   "metadata": {},
   "source": [
    "_First thing first_\n",
    "### Create Conda environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90eb0ce0",
   "metadata": {},
   "source": [
    "##### run below commands in terminal but make sure conda is installed or use anaconda prompt which you will get as part of anaconda installation\n",
    "\n",
    "1. `conda create -n envname python=3.9 ipykernel` \n",
    "it will create a conda env named envname and install python version 3.9 and a ipykernel inside this environment\n",
    "\n",
    "2. Activate the environment\n",
    "`conda activate envname`\n",
    "\n",
    "3. add newly created environment to the notebook as kernel\n",
    "`python -m ipykernel install --user --name=envname` \n",
    "\n",
    "4. install notebook inside the environment\n",
    "`pip install notebook`\n",
    "\n",
    "5. Now install all required dependencies to run this notebook\n",
    "\n",
    "* `pip install pandas`\n",
    "* `pip install numpy`\n",
    "* `pip install scikit-learn`\n",
    "* `pip install imblearn`\n",
    "* `pip install matplotlib`\n",
    "* `pip install mlflow`\n",
    "\n",
    "Now open the notebook using below command: (from the anaconda prompt inside conda environment)\n",
    "\n",
    "`jupyter notebook`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf5a6b9",
   "metadata": {},
   "source": [
    "#### Make sure python is used from your newly created environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fd81db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\envs\\mlflow\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3caf80a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.16\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5ff2b8",
   "metadata": {},
   "source": [
    "### Create functions for all the steps involved in complete model training lifecycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f0efd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed9e53b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    data = pd.read_csv(path)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5611082a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp_var_rate</th>\n",
       "      <th>cons_price_idx</th>\n",
       "      <th>cons_conf_idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr_employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>thu</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.444</td>\n",
       "      <td>-36.1</td>\n",
       "      <td>4.963</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>93.200</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>4.021</td>\n",
       "      <td>5195.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jun</td>\n",
       "      <td>thu</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>success</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>94.055</td>\n",
       "      <td>-39.8</td>\n",
       "      <td>0.729</td>\n",
       "      <td>4991.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>apr</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>93.075</td>\n",
       "      <td>-47.1</td>\n",
       "      <td>1.405</td>\n",
       "      <td>5099.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>success</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>92.201</td>\n",
       "      <td>-31.4</td>\n",
       "      <td>0.869</td>\n",
       "      <td>5076.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          job  marital          education  default housing loan  \\\n",
       "0   44  blue-collar  married           basic.4y  unknown     yes   no   \n",
       "1   53   technician  married            unknown       no      no   no   \n",
       "2   28   management   single  university.degree       no     yes   no   \n",
       "3   39     services  married        high.school       no      no   no   \n",
       "4   55      retired  married           basic.4y       no     yes   no   \n",
       "\n",
       "    contact month day_of_week  ...  campaign  pdays  previous     poutcome  \\\n",
       "0  cellular   aug         thu  ...         1    999         0  nonexistent   \n",
       "1  cellular   nov         fri  ...         1    999         0  nonexistent   \n",
       "2  cellular   jun         thu  ...         3      6         2      success   \n",
       "3  cellular   apr         fri  ...         2    999         0  nonexistent   \n",
       "4  cellular   aug         fri  ...         1      3         1      success   \n",
       "\n",
       "  emp_var_rate  cons_price_idx  cons_conf_idx  euribor3m  nr_employed  y  \n",
       "0          1.4          93.444          -36.1      4.963       5228.1  0  \n",
       "1         -0.1          93.200          -42.0      4.021       5195.8  0  \n",
       "2         -1.7          94.055          -39.8      0.729       4991.6  1  \n",
       "3         -1.8          93.075          -47.1      1.405       5099.1  0  \n",
       "4         -2.9          92.201          -31.4      0.869       5076.2  1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_data('https://raw.githubusercontent.com/TripathiAshutosh/dataset/main/banking.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcdca67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(data):\n",
    "    print(\"na values available in data \\n\")\n",
    "    print(data.isna().sum())\n",
    "    data = data.dropna()\n",
    "    print(\"after droping na values \\n\")\n",
    "    print(data.isna().sum())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d378c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data):\n",
    "    data['education']=np.where(data['education'] =='basic.9y', 'Basic', data['education'])\n",
    "    data['education']=np.where(data['education'] =='basic.6y', 'Basic', data['education'])\n",
    "    data['education']=np.where(data['education'] =='basic.4y', 'Basic', data['education'])\n",
    "    \n",
    "    cat_vars=['job','marital','education','default','housing','loan','contact','month','day_of_week','poutcome']\n",
    "    for var in cat_vars:\n",
    "        cat_list='var'+'_'+var\n",
    "        cat_list = pd.get_dummies(data[var], prefix=var)\n",
    "        data1=data.join(cat_list)\n",
    "        data=data1\n",
    "\n",
    "    cat_vars=['job','marital','education','default','housing','loan','contact','month','day_of_week','poutcome']\n",
    "    data_vars=data.columns.values.tolist()\n",
    "    to_keep=[i for i in data_vars if i not in cat_vars]\n",
    "    \n",
    "    final_data=data[to_keep]\n",
    "    \n",
    "    \n",
    "    final_data.columns = final_data.columns.str.replace('.','_')\n",
    "    final_data.columns = final_data.columns.str.replace(' ','_')\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6f78530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(final_data):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X = final_data.loc[:, final_data.columns != 'y']\n",
    "    y = final_data.loc[:, final_data.columns == 'y']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,stratify = y, random_state=47)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3eb6095a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def over_sampling_target_class(X_train, y_train):\n",
    "    ### Over-sampling using SMOTE \n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    os = SMOTE(random_state=0)\n",
    "\n",
    "    columns = X_train.columns\n",
    "    os_data_X,os_data_y=os.fit_resample(X_train, y_train)\n",
    "\n",
    "    os_data_X = pd.DataFrame(data=os_data_X,columns=columns )\n",
    "    os_data_y= pd.DataFrame(data=os_data_y,columns=['y'])\n",
    "    # we can Check the numbers of our data\n",
    "    print(\"length of oversampled data is \",len(os_data_X))\n",
    "    print(\"Number of no subscription in oversampled data\",len(os_data_y[os_data_y['y']==0]))\n",
    "    print(\"Number of subscription\",len(os_data_y[os_data_y['y']==1]))\n",
    "    print(\"Proportion of no subscription data in oversampled data is \",len(os_data_y[os_data_y['y']==0])/len(os_data_X))\n",
    "    print(\"Proportion of subscription data in oversampled data is \",len(os_data_y[os_data_y['y']==1])/len(os_data_X))\n",
    "    \n",
    "    X_train = os_data_X\n",
    "    y_train = os_data_y['y']\n",
    " \n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c85667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_basic_classifier(X_train,y_train):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    model = RandomForestClassifier(n_estimators=101)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce3c96bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_test_data(model,X_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a475cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_prob_on_test_data(model,X_test):\n",
    "    y_pred = model.predict_proba(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07ccc67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_true, y_pred, y_pred_prob):\n",
    "    from sklearn.metrics import accuracy_score,precision_score,recall_score,log_loss\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    entropy = log_loss(y_true, y_pred_prob)\n",
    "    return {'accuracy': round(acc, 2), 'precision': round(prec, 2), 'recall': round(recall, 2), 'entropy': round(entropy, 2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9dab017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca1aeebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_roc_auc_plot(clf, X_data, y_data):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn import metrics\n",
    "    metrics.plot_roc_curve(clf, X_data, y_data) \n",
    "    plt.savefig('roc_auc_curve.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db16c987",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_confusion_matrix_plot(clf, X_test, y_test):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import plot_confusion_matrix\n",
    "    plot_confusion_matrix(clf, X_test, y_test)\n",
    "    plt.savefig('confusion_matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3aec48cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_parameter_tuning(X_train, y_train):\n",
    "    # define random parameters grid\n",
    "    n_estimators = [5,21,51,101] # number of trees in the random forest\n",
    "    max_features = ['auto', 'sqrt'] # number of features in consideration at every split\n",
    "    max_depth = [int(x) for x in np.linspace(10, 120, num = 12)] # maximum number of levels allowed in each decision tree\n",
    "    min_samples_split = [2, 6, 10] # minimum sample number to split a node\n",
    "    min_samples_leaf = [1, 3, 4] # minimum sample number that can be stored in a leaf node\n",
    "    bootstrap = [True, False] # method used to sample data points\n",
    "\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                    'max_features': max_features,\n",
    "                    'max_depth': max_depth,\n",
    "                    'min_samples_split': min_samples_split,\n",
    "                    'min_samples_leaf': min_samples_leaf,\n",
    "                    'bootstrap': bootstrap\n",
    "                  }\n",
    "    \n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    classifier = RandomForestClassifier()\n",
    "    model_tuning = RandomizedSearchCV(estimator = classifier, param_distributions = random_grid,\n",
    "                   n_iter = 100, cv = 5, verbose=2, random_state=35, n_jobs = -1)\n",
    "    model_tuning.fit(X_train, y_train)\n",
    "\n",
    "    print ('Random grid: ', random_grid, '\\n')\n",
    "    # print the best parameters\n",
    "    print ('Best Parameters: ', model_tuning.best_params_, ' \\n')\n",
    "\n",
    "    best_params = model_tuning.best_params_\n",
    "    \n",
    "    n_estimators = best_params['n_estimators']\n",
    "    min_samples_split = best_params['min_samples_split']\n",
    "    min_samples_leaf = best_params['min_samples_leaf']\n",
    "    max_features = best_params['max_features']\n",
    "    max_depth = best_params['max_depth']\n",
    "    bootstrap = best_params['bootstrap']\n",
    "    \n",
    "    model_tuned = RandomForestClassifier(n_estimators = n_estimators, min_samples_split = min_samples_split,\n",
    "                                         min_samples_leaf= min_samples_leaf, max_features = max_features,\n",
    "                                         max_depth= max_depth, bootstrap=bootstrap) \n",
    "    model_tuned.fit( X_train, y_train)\n",
    "    return model_tuned,best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8aeb7b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8acce9f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = load_data('https://raw.githubusercontent.com/TripathiAshutosh/dataset/main/banking.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "376d0587",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "na values available in data \n",
      "\n",
      "age               0\n",
      "job               0\n",
      "marital           0\n",
      "education         0\n",
      "default           0\n",
      "housing           0\n",
      "loan              0\n",
      "contact           0\n",
      "month             0\n",
      "day_of_week       0\n",
      "duration          0\n",
      "campaign          0\n",
      "pdays             0\n",
      "previous          0\n",
      "poutcome          0\n",
      "emp_var_rate      0\n",
      "cons_price_idx    0\n",
      "cons_conf_idx     0\n",
      "euribor3m         0\n",
      "nr_employed       0\n",
      "y                 0\n",
      "dtype: int64\n",
      "after droping na values \n",
      "\n",
      "age               0\n",
      "job               0\n",
      "marital           0\n",
      "education         0\n",
      "default           0\n",
      "housing           0\n",
      "loan              0\n",
      "contact           0\n",
      "month             0\n",
      "day_of_week       0\n",
      "duration          0\n",
      "campaign          0\n",
      "pdays             0\n",
      "previous          0\n",
      "poutcome          0\n",
      "emp_var_rate      0\n",
      "cons_price_idx    0\n",
      "cons_conf_idx     0\n",
      "euribor3m         0\n",
      "nr_employed       0\n",
      "y                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "cleaned_data = data_cleaning(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8e4a40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_13936\\4067079169.py:20: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  final_data.columns = final_data.columns.str.replace('.','_')\n"
     ]
    }
   ],
   "source": [
    "final_data = preprocessing(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7bbb6b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8da133cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of oversampled data is  51166\n",
      "Number of no subscription in oversampled data 25583\n",
      "Number of subscription 25583\n",
      "Proportion of no subscription data in oversampled data is  0.5\n",
      "Proportion of subscription data in oversampled data is  0.5\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = over_sampling_target_class(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c0e3da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = training_basic_classifier(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b485e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict_on_test_data(model,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55d29fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19e4fd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = predict_prob_on_test_data(model,X_test) #model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f7765b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98019802, 0.01980198],\n",
       "       [0.99009901, 0.00990099],\n",
       "       [0.94059406, 0.05940594],\n",
       "       ...,\n",
       "       [1.        , 0.        ],\n",
       "       [0.64356436, 0.35643564],\n",
       "       [1.        , 0.        ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ceef3c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_metrics = get_metrics(y_test, y_pred, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2bdeda22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.91, 'precision': 0.63, 'recall': 0.51, 'entropy': 0.2}\n"
     ]
    }
   ],
   "source": [
    "print(run_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2ff3c7fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create_roc_auc_plot(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4ce51f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_confusion_matrix_plot(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc429fce",
   "metadata": {},
   "source": [
    "### MLFlow work Starts from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e5756180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.91, 'precision': 0.61, 'recall': 0.52, 'entropy': 0.2}\n"
     ]
    }
   ],
   "source": [
    "experiment_name = \"basic_classifier\" ##basic classifier\n",
    "run_name=\"term_deposit\"\n",
    "run_metrics = get_metrics(y_test, y_pred, y_pred_prob)\n",
    "print(run_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "af260494",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/02/03 12:08:49 INFO mlflow.tracking.fluent: Experiment with name 'basic_classifier' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run - term_deposit is logged to Experiment - basic_classifier\n"
     ]
    }
   ],
   "source": [
    "create_experiment(experiment_name,run_name,run_metrics,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828a00fb",
   "metadata": {},
   "source": [
    "### Function to create an experiment in MLFlow and log parameters, metrics and artifacts files like images etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "26f2c095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_experiment(experiment_name,run_name, run_metrics,model, confusion_matrix_path = None, \n",
    "                      roc_auc_plot_path = None, run_params=None):\n",
    "    import mlflow\n",
    "    mlflow.set_tracking_uri(\"http://localhost:5000\") #uncomment this line if you want to use any database like sqlite as backend storage for model\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        \n",
    "        if not run_params == None:\n",
    "            for param in run_params:\n",
    "                mlflow.log_param(param, run_params[param])\n",
    "            \n",
    "        for metric in run_metrics:\n",
    "            mlflow.log_metric(metric, run_metrics[metric])\n",
    "        \n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "        \n",
    "#         if not confusion_matrix_path == None:\n",
    "#             mlflow.log_artifact(confusion_matrix_path, 'confusion_materix')\n",
    "            \n",
    "#         if not roc_auc_plot_path == None:\n",
    "#             mlflow.log_artifact(roc_auc_plot_path, \"roc_auc_plot\")\n",
    "        \n",
    "        mlflow.set_tag(\"tag1\", \"Random Forest\")\n",
    "        mlflow.set_tags({\"tag2\":\"Randomized Search CV\", \"tag3\":\"Production\"})\n",
    "            \n",
    "    print('Run - %s is logged to Experiment - %s' %(run_name, experiment_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c5b47c",
   "metadata": {},
   "source": [
    "### Create another experiment after tuning hyperparameters and log the best set of parameters for which model gives the optimal performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5a0d0f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Random grid:  {'n_estimators': [5, 21, 51, 101], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120], 'min_samples_split': [2, 6, 10], 'min_samples_leaf': [1, 3, 4], 'bootstrap': [True, False]} \n",
      "\n",
      "Best Parameters:  {'n_estimators': 21, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'max_depth': 40, 'bootstrap': False}  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "experiment_name = \"optimized model\"\n",
    "run_name=\"Random_Search_CV_Tuned_Model\"\n",
    "model_tuned,best_params = hyper_parameter_tuning(X_train, y_train)\n",
    "run_params = best_params\n",
    "\n",
    "y_pred = predict_on_test_data(model_tuned,X_test) #will return the predicted class\n",
    "y_pred_prob = predict_prob_on_test_data(model_tuned,X_test) #model.predict_proba(X_test)\n",
    "run_metrics = get_metrics(y_test, y_pred, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "163fd982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.91, 'precision': 0.61, 'recall': 0.52, 'entropy': 0.2}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2d8bafa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators 21\n",
      "min_samples_split 2\n",
      "min_samples_leaf 3\n",
      "max_features sqrt\n",
      "max_depth 40\n",
      "bootstrap False\n"
     ]
    }
   ],
   "source": [
    "for param in run_params:\n",
    "    print(param, run_params[param])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f520e4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run - Random_Search_CV_Tuned_Model is logged to Experiment - optimized model\n"
     ]
    }
   ],
   "source": [
    "create_experiment(experiment_name,run_name,run_metrics,model_tuned,'confusion_matrix.png', 'roc_auc_curve.png',run_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a466fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7da88ce8",
   "metadata": {},
   "source": [
    "\n",
    "### if want to use the model registry feature, we need a database.\n",
    "\n",
    "#### _If you have MySQL installed then you can use the below command:_\n",
    "\n",
    "1. Create a database to use as an MLflow backend tracking server.\n",
    "\n",
    "`CREATE DATABASE mlflow_tracking_database;`\n",
    "\n",
    "2. Start MLflow tracking server using MySQL as a backend tracking store.\n",
    "` mlflow server \\\n",
    "   --backend-store-uri  mysql+pymysql://root@localhost/mlflow_tracking_database \\ \n",
    "   --default-artifact-root  file:/./mlruns \\\n",
    "   -h 0.0.0.0 -p 5000`\n",
    "\n",
    "\n",
    "3. Set the MLflow tracking uri (within code section).\n",
    "\n",
    "  mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "\n",
    "#### _If you have sqlite installed then you can use the below command:_\n",
    "\n",
    "1. Start MLflow tracking server using sqlite as a backend tracking store.\n",
    "\n",
    "`mlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./artifacts --host 0.0.0.0 --port 5000`\n",
    "\n",
    "\n",
    "2. Set the MLflow tracking uri (within code section).\n",
    "    \n",
    "    mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "\n",
    "\n",
    "You can also follow the official documentation for more information on backend database for model registry\n",
    "\n",
    "https://www.mlflow.org/docs/latest/model-registry.html#model-registry-workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51dadd7",
   "metadata": {},
   "source": [
    "## Next steps:\n",
    "\n",
    "Using MLFlow\n",
    "* How deploy models from model registry\n",
    "* Model serving both batch serving and online serving\n",
    "* MLFlow pipelines\n",
    "* Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea7af37",
   "metadata": {},
   "source": [
    "# Thank You "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac6b8d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow",
   "language": "python",
   "name": "mlflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
